# NVIDIA NeMo Framework

NeMo Framework is NVIDIA's GPU accelerated, end-to-end training framework for large language models (LLMs), multi-modal models and speech models. It enables seamless scaling of training (both pretraining and post-training) workloads from single GPU to thousand-node clusters for both ðŸ¤—Hugging Face, Megatron, and PyTorch models.

This site hosts documentation, tutorials, and insights about NeMo's core components and integrations.

## Latest Blog Posts

### [Reinforcement Learning with NVIDIA NeMo-RL: Reproducing a DeepScaleR Recipe Using GRPO](blog/posts/nemo-rl-deepscaler-grpo/index.md)

*July 8, 2025*

Learn how to use NVIDIA NeMo-RL to reproduce a DeepScaleR recipe using Group Relative Policy Optimization (GRPO) for training high-performing reasoning models. This comprehensive guide covers the step-by-step process of setting up, training, and evaluating models using the DeepScaleR methodology.

---

[View all blog posts â†’](blog/index.md){ .md-button }

## NeMo Framework Components

<div class="grid cards" markdown>

-   ðŸš€ __NeMo-RL__

    ---

    Scalable toolkit for efficient model reinforcement learning and post-training. Includes algorithms like DPO, GRPO, and support for everything from single-GPU prototypes to thousand-GPU deployments.

    [ðŸš€ GitHub Repository](https://github.com/NVIDIA-NeMo/RL){ .md-button }

    [ðŸ“– Documentation](https://docs.nvidia.com/nemo/rl/latest/index.html){ .md-button }

</div>

## License

Apache 2.0 licensed with third-party attributions documented in each repository.
